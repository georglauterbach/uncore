{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"The unCORE Operating System Kernel","text":"","tags":["home","introduction","overview"]},{"location":"#introduction","title":"Introduction","text":"<p>Welcome to the official unCORE operating system kernel documentation. unCORE is</p> <ul> <li>an educational, modern operating system kernel</li> <li>completely written in pure, idiomatic Rust (and assembly where required),</li> <li>licensed under the GNU Public License v3 or later, except for those parts (lines of code from libraries used in this project) already licensed under other licenses,</li> <li>documented in its entirety: the code via Doc comments, the rest via Markdown and GitHub Pages.</li> </ul> <p>Everything you need to know about how to work on unCORE can be found under Development. The Kernel Architecture section contains all the information about the kernel's internal structure and composition. The Testing page contains information on unit- and integration tests.</p> <p>The Second Half of the Documentation</p> <p>This documentation is only one half of the whole documentation that is available. The other part is the code documentation that can be build with <code>cd code &amp;&amp; cargo run -q -- doc [--help]</code>. The code itself is extensively documented with doc comments, so make sure to also check out the code documentation!</p> <p>Writing a Kernel Subsystem or Component From Scratch</p> <p>unCORE is (currently) suited to building kernel subsystems (scheduling, paging, etc.) or components (threads, drivers, etc.) from scratch. This is because unCORE provides a straight forward documentation and unCORE is very easy to get started with. The (current) code base is small and easy to grasp.</p> <p>If you always wanted to build anything inside a kernel, this is the project that gets you going! Moreover, merge requests are welcome </p>","tags":["home","introduction","overview"]},{"location":"#vision","title":"Vision","text":"<p>As of now, unCORE is an educational project that does not run real software. Anyone interested in Rust, whether they are beginners or experts, can start working on this project. Its extensive documentation eases working with the code tremendously. By fully sticking to Rust (for everything, including the build), we simplify working with the code across all disciplines: building, running, debugging, testing. Rust also provides excellent abstractions and new programming concepts that older languages like C simply lack.</p> <p>Abstraction | Edsger Wybe Dijkstra</p> <p>Abstraction is not about vagueness, it is about being precise on a new semantic level.</p>","tags":["home","introduction","overview"]},{"location":"development/","title":"Development","text":"<p>Preliminary Information</p> <p>We expect you to have some experience with Rust: you need not be an expert, but unCORE requires you to understand the basics of the programming language. If you are a complete beginner, we highly recommend you to read the official Rust book.</p>","tags":["development","guidelines","workflow"]},{"location":"development/#getting-started","title":"Getting Started","text":"<p>After you have forked the repository, you can clone it. All Rust code resides in <code>code/</code>. The documentation lives in <code>documentation/</code>. <code>misc/</code> contains miscellaneous files, e.g., GDB initialization files, shell aliases, etc. In the <code>.github/</code> directory you can find CI/CD and GitHub-related configuration files. The <code>code/</code> directory is a Cargo Workspace.</p> <p>If you want to start working on unCORE, go ahead and install Rust and <code>mold</code>. When you later work on this project, you will be told if you're missing other dependencies (like <code>qemu-system-riscv64</code> or <code>jq</code>).</p>","tags":["development","guidelines","workflow"]},{"location":"development/#workflow","title":"Workflow","text":"","tags":["development","guidelines","workflow"]},{"location":"development/#about-the-workspace","title":"About the Workspace","text":"<p>The workspace that lives inside <code>code/</code> has a \"main\" binary and \"proper\" workspace members. The main binary lives in <code>code/src/</code>. An example for a workspace member is <code>code/uncore/</code>; this is where the kernel code resides.</p> <p>You now have two options:</p> <ol> <li>When using <code>cargo run -- &lt;COMMAND&gt;</code>, the main binary is invoked, which contains code to handle the other workspace members; and this is the trick to using only Rust and no build system (other than Cargo). The default binary, when invoked, invokes Cargo again with all the correct arguments and options to properly build the kernel. It also performs required checks (e.g., on dependencies) beforehand.</li> <li>When you do not want to install Rust, you can also use a build container. This is also used in the CI to build and test unCORE.</li> </ol> <p>With such a workspace, unCORE does not require a build system or additional build configuration in files like <code>.cargo/config.toml</code> that are inflexible.</p> <p>The actual kernel code lives in <code>code/uncore/src/</code>. In this directory, you fill find <code>main.rs</code>, <code>lib.rs</code> and <code>library/</code>. <code>main.rs</code> is recognized by Cargo automatically as a binary. It contains the kernel's entry point (called by a bootloader). <code>lib.rs</code> is automatically recognized by Cargo as a library target. This is useful because we can put all kernel code in the library, whose root is <code>lib.rs</code>, and just call it from binaries - such binaries are not only <code>main.rs</code>, but integration tests (in <code>code/uncore/tests/</code>) as well! <code>library/</code> is the top-level directory that is used by <code>lib.rs</code> as a module (i.e., with <code>mod library;</code>); <code>library/</code> exists in order to not have all top-level modules in the top-level directory.</p>","tags":["development","guidelines","workflow"]},{"location":"development/#working-with-uncore","title":"Working with unCORE","text":"<p>When working on unCORE, you use the workspace's main binary. You run it by executing <code>cargo run</code>, and you provide all arguments to it in the same command. To see which commands and options the binary supports, run the following commands:</p> <pre><code>$ cd code\n$ cargo run -- help # (1)\nCompiling uncore-helper v1.0.0-alpha1 (/path/to/uncore/code)\nFinished dev [unoptimized + debuginfo] target(s) in 1.56s\nRunning `target/debug/uncore-helper help`\n\nWorkspace member that eases working with unCORE.\n...\n</code></pre> <ol> <li>The <code>--</code> is used to separate arguments for Cargo from those that we want to pass to our binary. In this case, <code>run</code> is an argument to Cargo, <code>help</code> is an argument to our binary.</li> </ol> <p>There are different commands available: The <code>run</code> command will run unCORE; when you use <code>run --debug</code>, you can attach GDB; when you use <code>u-test</code>, you run unit-tests. Using the <code>help</code> (or <code>--help</code> or <code>-h</code>) command will always show which commands you can run. These patterns are used ubiquitously; unCORE's CI also makes use of these commands.</p> <p>To further ease the process, aliases are defined in <code>code/.cargo/config.toml</code>. Hence, to run the kernel, you may use <code>cargo _run</code>. Have a look at the file to see which other aliases are defined.</p> How Is the Kernel Actually Built? <p>As mentioned earlier, the kernel is actually built by the main workspace binary (residing in <code>code/src/</code>). The function that invokes Cargo is <code>code/src/command.rs:build</code>. Cargo then builds the kernel whose code resides in <code>code/uncore/src/</code>.</p> <p>The \"heavy lifting\" is done by Cargo. The workspace main binary \"only\" takes care of checking dependencies and invoking Cargo correctly, i.e., with the correct target (architecture), environment variables used when building, linker script (and linker), etc.</p>","tags":["development","guidelines","workflow"]},{"location":"development/#development-container","title":"Development Container","text":"<p>We strongly recommend you to use the Development Container that ships with the repository. This way, all dependencies come with the container image and you do not need to install anything manually on your host. You will need to have an OCI-compatible container runtime (e.g., Docker with Containerd, Podman with crun, etc.) installed and an IDE that supports the Development Container standard (e.g., Visual Studio Code with the <code>ms-vscode-remote.remote-containers</code> (\"Dev Containers\") extension installed). Using Development Containers has the additional upside that common tasks (like building or running unCORE) can then easily be handled by the IDE as well, because the appropriate configurations will be placed in the correct locations.</p> <p>The configuration for the Development Container is located in the <code>.devcontainer/</code> directory.</p>","tags":["development","guidelines","workflow"]},{"location":"development/#conventions","title":"Conventions","text":"<p>Please stick to the style and naming conventions you encounter in this project. Clippy is used to check and lint the Rust code in this project. rustfmt is used to format (and check) the code. An appropriate <code>code/.rustfmt.toml</code> is already provided. Similarly, we use EditorConfig. Conventions are enforced by our CI.</p>","tags":["development","guidelines","workflow"]},{"location":"development/#debugging","title":"Debugging","text":"<p>The workspace main binary provides an easy way to debug unCORE. Debugging is supported for running the plain kernel binary, the unit-, and the integration-tests. All you need to do is add the <code>--debug</code> flag to these targets:</p> <pre><code>$ cargo run -q -- -vv run --debug\n...\nDEBUG Checking run-time dependencies\nTRACE Checking run-time dependencies required for debugging\n...\nINFO  Debugging unCORE\nDEBUG You may use 'gdb-multiarch -q -x code/misc/gdb/&lt;FILE&gt;' to attach now\nTRACE Remember: 'Ctrl-A x' will exit QEMU\n...\n</code></pre> <p>You can then attach to QEMU with GDB. An example initialization script for GDB can found at <code>misc/gdb/init.gdb</code>.</p> <p>Note</p> <p>The command also works for unit-tests: <code>cargo run -q -- -vv u-test --debug</code>. For integration tests, you will need to specify the test name in conjunction with the <code>--debug</code> flag: <code>cargo run -q -- -vv i-test --debug --test &lt;TEST NAME&gt;</code>.</p>","tags":["development","guidelines","workflow"]},{"location":"testing/","title":"Testing the Kernel","text":"<p>Abstract</p> <p>unCORE provides unit- and integration-tests. Integration tests are found under <code>code/uncore/tests/</code>. Unit-test are located in the kernel source code as part of the kernel's library. Note that linting (the kernel but also all other parts of this project) is an important part of code quality enforcement. Hence, we lint the whole codebase during CI.</p>","tags":["testing","unit tests","integration tests","linting"]},{"location":"testing/#unit-tests","title":"Unit Tests","text":"<p>Unit tests for the kernel are associated with <code>lib.rs</code> and not with <code>main.rs</code>. Unit tests are declared via the <code>#[test_case]</code> directive above the test:</p> <pre><code>/// ### Sanity Check\n///\n/// This tests is just here for sanity's sake to make\n/// sure tests behave correctly at the most basic level.\n#[test_case]\nfn trivial_assertion() {\n  const ONE: u8 = 1;\n  assert_eq!(1, ONE);\n  assert_eq!(ONE, 1);\n}\n</code></pre> <p>A simple test runner implementation (located in <code>code/uncore/src/library/test.rs</code>) executes all tests one after another when the unit-test binary is run in QEMU. Conditional compilation (with <code>#[cfg(test)]</code>) indicates code that only runs when the unit-test binary is created. Because the library part of unCORE runs the unit tests, it has a pseudo entry function that acts like <code>main()</code>:</p> <pre><code>/// The unit-test entry point of `lib.rs`. This function\n/// is run when unit tests for `lib.rs` are run.\n#[cfg(all(target_arch = \"riscv64\", test))]\n#[riscv_rt::entry]\nfn riscv64_entry() -&gt; ! { ... }\n</code></pre> <p>To run unit tests, use <code>cargo run -- u-test</code>.</p>","tags":["testing","unit tests","integration tests","linting"]},{"location":"testing/#integration-tests","title":"Integration Tests","text":"<p>Integration tests reside under <code>code/uncore/tests/</code>. They test bigger parts of the whole kernel to make sure all parts work together nicely. Some integration tests do not use a test harness.</p> <p>To run integration tests, use <code>cargo run -- i-test</code>.</p> Running \"Unit-Tests\" Inside an Integration Test <p>If you want to run \"unit-tests\" inside an integration test, you require a test runner. The library part of unCORE provides such a runner:</p> <pre><code>// Use custom test runners. Since we cannot use the standard\n// library, we have to use our own test framework.\n#![feature(custom_test_frameworks)]\n// With our own test framework, we have to define which function\n// runs our tests.\n#![test_runner(uncore::test::runner)]\n// We will have to re-export the actual test runner above with\n// a new name so cargo is not confused.\n#![reexport_test_harness_main = \"__test_runner\"]\n</code></pre> <p>You can then call <code>__test_runner();</code> to run all tests marked with <code>#[test_case]</code>.</p>","tags":["testing","unit tests","integration tests","linting"]},{"location":"testing/#how-test-are-implemented","title":"How Test are Implemented","text":"<p>Running kernel tests is a bit more tricky than you might think. We will need to run them inside QEMU, and on top of that, <code>cargo</code> does not (yet) provide a nice interface to list the files it created for the tests. The trick is to supply the <code>--no-run</code> and <code>--message-output=json</code> flags when running <code>cargo test ...</code> and then parse the binary file paths with <code>jq</code>. These file paths can then be used in conjunction with QEMU. Relying on special files like <code>.cargo/config.toml</code> would be infeasible as they introduce other pitfalls and have critical downsides (like forcing the whole workspace to a target).</p>","tags":["testing","unit tests","integration tests","linting"]},{"location":"testing/#continuous-integration-ci","title":"Continuous Integration (CI)","text":"<p>Continuous Integration (CI) is a critical part of modern software development. This project uses GitHub Actions. When you open a PR or when pushing on a branch, [GitHub Actions] run to check and test your code. These checks consist of linting as well as unit- and integration tests.</p> <p>Praise be Linters</p> <p>A linter that is probably going to be very annoying, nerve-wrecking, but also essential in the end is <code>clippy</code>. You may have noticed the linting targets in <code>code/Cargo.toml</code>. unCORE's configuration enables various linting targets for the whole kernel. If you do not want <code>clippy</code> to eat you alive wheh checking a merge request (GitHub calls them \"Pull Request\"), fix the lints locally. You can run <code>cargo run -- check</code> to check for all kinds of linting issues.</p>","tags":["testing","unit tests","integration tests","linting"]},{"location":"community/changelog/","title":"Changelog","text":"","tags":["community","changelog"]},{"location":"community/changelog/#about","title":"About","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>","tags":["community","changelog"]},{"location":"community/changelog/#changes","title":"Changes","text":"","tags":["community","changelog"]},{"location":"community/changelog/#unreleased","title":"Unreleased","text":"<p>Note</p> <p>Changes and additions listed here are contained in the <code>:edge</code> image tag. These changes may not be as stable as released changes.</p>","tags":["community","changelog"]},{"location":"community/code_of_conduct/","title":"Code of Conduct","text":"<p>version 1.2, 09 Nov 2023</p>","tags":["community","code of conduct"]},{"location":"community/code_of_conduct/#our-pledge","title":"Our Pledge","text":"<p>Computing professionals' actions change the world. To act responsibly, they should reflect upon the wider impacts of their work, consistently supporting the public good. We as members, contributors, and leaders pledge to make participation in this community a professional and welcoming experience for everyone.</p>","tags":["community","code of conduct"]},{"location":"community/code_of_conduct/#responsibilities","title":"Responsibilities","text":"<p>Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.</p> <p>Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.</p>","tags":["community","code of conduct"]},{"location":"community/code_of_conduct/#scope","title":"Scope","text":"<p>This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event.</p>","tags":["community","code of conduct"]},{"location":"community/code_of_conduct/#enforcement","title":"Enforcement","text":"<p>Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement. All complaints will be reviewed and investigated promptly and fairly.</p> <p>All community leaders are obligated to respect the privacy and security of the reporter of any incident.</p>","tags":["community","code of conduct"]},{"location":"community/overview/","title":"Community-Related Documents","text":"<p>This section of the documentation contains information on community-related information, such as</p> <ul> <li>Changelog</li> <li>Code of Conduct</li> <li>Security</li> <li>References and Sources</li> </ul>","tags":["community"]},{"location":"community/references_and_sources/","title":"References and Sources","text":"<p>This project was and is heavily inspired by the following projects:</p> <ol> <li>Phillip Oppermann | BlogOS</li> <li>Matthias Totschnig | Hello, RISC-V and QEMU</li> <li>Stephen Marz | RISC-V OS using Rust</li> <li>Henry Gressmann | Operating Systems in Rust</li> </ol> <p>Other good learning resources:</p> <ol> <li>Stephen Marz | RISC-V Assembly Language</li> <li>RISC-V Non-ISA Specifications on GitHub | RISC-V Assembly Programmer's Manual</li> </ol>","tags":["community","references and sources"]},{"location":"community/security/","title":"Security Policy","text":"<p>version 1.0, 14 Jan 2022</p>","tags":["community","security","security policy"]},{"location":"community/security/#supported-versions","title":"Supported Versions","text":"<p>We support the latest version of our kernel modules and the kernel with security updates. That is to say that we do not backport security updates to older versions as of now.</p>","tags":["community","security","security policy"]},{"location":"community/security/#checks","title":"Checks","text":"<p>For every pull requests, and on schedule (every Saturday), a GitHub workflow under <code>.github/workflows/security.yml</code> called \"Security Audit\" is run. This workflow will check for any security vulnerabilities introduced by crates used in this project.</p>","tags":["community","security","security policy"]},{"location":"community/security/#reporting-a-vulnerability","title":"Reporting a Vulnerability","text":"<p>unCORE takes security very seriously. We will follow the rule of responsible disclosure in the future. As of now, please just open an issue. As there is no centralized domain / mail service, opening an issue is the easiest way for now.</p>","tags":["community","security","security policy"]},{"location":"community/security/#responsible-disclosure","title":"Responsible Disclosure","text":"<p>If you discover a vulnerability in unCORE, please first contact one of the maintainers privately. Users who report bugs will optionally be credited for the discovery.</p> <p>We urge you not to disclose the bug publicly at least until we've had a reasonable chance to fix it, and to clearly communicate any public disclosure timeline in your initial contact with us. If you do not have a particular public disclosure timeline, we will clearly communicate ours as we publish security advisories.</p>","tags":["community","security","security policy"]},{"location":"community/security/#process","title":"Process","text":"<ol> <li>A user privately reports a potential vulnerability.</li> <li>The core team reviews the report and ascertain if additional information is required.</li> <li>The core team reproduces the bug.</li> <li>The bug is patched, and if possible the user reporting te bug is given access to a fixed version or git patch.</li> <li>The fix is confirmed to resolve the vulnerability.</li> <li>The fix is released.</li> <li>The security advisory is published sometime after users have had a chance to update.</li> </ol>","tags":["community","security","security policy"]},{"location":"kernel_architecture/overview/","title":"The Kernel Architecture","text":"","tags":["kernel architecture","kernel architecture","kernel structure","kernel structure","overview"]},{"location":"kernel_architecture/overview/#architecture-dependent-information","title":"Architecture-Dependent Information","text":"<p>Architecture-specific code resides in <code>code/uncore/src/library/arch/</code>. The documentation for architecture-specific functionality is provided in separate articles:</p> <ul> <li>RISC-V</li> <li>Other Architectures: unCORE does currently not support architectures other than RISC-V.</li> </ul>","tags":["kernel architecture","kernel architecture","kernel structure","kernel structure","overview"]},{"location":"kernel_architecture/overview/#architecture-independent-information","title":"Architecture-Independent Information","text":"<p>There are aspects of the kernel code that are independent of the architecture: the directory and file layout of the kernel source code, mechanisms above<sup>1</sup> the HAL, etc. The following subsections describe and explain the functionality of unCORE above the HAL.</p>","tags":["kernel architecture","kernel architecture","kernel structure","kernel structure","overview"]},{"location":"kernel_architecture/overview/#memory","title":"Memory","text":"<p>This section (and the corresponding implementation) is TODO.</p> <p>The kernel does currently not support PVM. The heap implementation that is currently in place uses pre-defined memory (already known at link-time).</p>","tags":["kernel architecture","kernel architecture","kernel structure","kernel structure","overview"]},{"location":"kernel_architecture/overview/#threads-scheduling","title":"Threads &amp; Scheduling","text":"<p>This section (and the corresponding implementation) is TODO.</p>","tags":["kernel architecture","kernel architecture","kernel structure","kernel structure","overview"]},{"location":"kernel_architecture/overview/#hardware-abstraction","title":"Hardware Abstraction","text":"<p>This section (and the corresponding implementation) is TODO.</p> <ol> <li> <p>\"Above\" refers to using the (HAL) instead of providing functionality for it to work (which one would refer to as \"below\"). Drivers, for example, reside \"below\" the HAL.\u00a0\u21a9</p> </li> </ol>","tags":["kernel architecture","kernel architecture","kernel structure","kernel structure","overview"]},{"location":"kernel_architecture/risc_v/","title":"RISC-V","text":"","tags":["kernel architecture","kernel architecture","kernel structure","kernel structure","RISC-V"]},{"location":"kernel_architecture/risc_v/#bootstrapping","title":"Bootstrapping","text":"<p>The boot-flow is tied to the privilege modes on each architecture. For the purpose of simplicity, this documentation covers RISC-V exemplarily.</p> <p>RISC-V has three privilege levels:</p> <ol> <li>Machine Mode: This is the level with the most privilege; firmware like OpenSBI runs here.</li> <li>Supervisor Mode: This privilege level is where our kernel runs.</li> <li>User Mode: This is the level with the least privilege; typically, user processes run here.</li> </ol> <p>Boot-Flow on RISC-V | Henry Gressmann</p> <p>Compared to other CPU Architectures, RISC-V's boot process is straightforward. We're using OpenSBI as our Supervisor Execution Environment (SEE), our Machine Mode (M-Mode) run-time firmware. Supervisor Binary Interface (SBI) is a standard interface for interacting with the SEE, and OpenSBI is an implementation of this standard.</p> <p>When running inside QEMU, a Jump Address (<code>0x8020_0000</code>) is used. QEMU will load our kernel into memory at this address, then jump to address <code>0x800_0000</code> where OpenSBI is located, which will then jump to <code>0x8020_0000</code>, where our kernel is located.</p> Traditional vs QEMU RISC-V Boot Flow <p>The imagery was developed by Henry Gressmann.</p> <p>While a traditional boot flow looks like this:</p> <pre><code>    System ROM           System ROM         Disk / Network       Disk / Network\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Device         \u2502   | First Stage    \u2502   \u2502 Second Stage   \u2502   \u2502                \u2502\n\u2502 Specific       \u251c\u2500\u2500&gt;| Bootloader     \u251c\u2500\u2500&gt;\u2502 Bootloader     \u251c\u2500\u2500&gt;\u2502 Kernel         \u2502\n\u2502 Firmware       \u2502   | (e.g., UEFI)   \u2502   \u2502 (e.g, Grub 2)  \u2502   \u2502                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n                      Loads the Second     Loads the kernel\n                      Stage Bootloader,    into memory, e.g.\n                      e.g., from address   from disk.\n                      specified in GPT.\n</code></pre> <p>The QEMU RISC-V is simplified and looks like this:</p> <pre><code>    System ROM              RAM                  RAM\n                        0x8000_0000          0x8020_0000\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Device         \u2502   |                \u2502   \u2502                \u2502\n\u2502 Specific       \u251c\u2500\u2500&gt;| OpenSBI        \u251c\u2500\u2500&gt;\u2502 Kernel         \u2502\n\u2502 Firmware       \u2502   |                \u2502   \u2502                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n  M-Mode              M-Mode               S-Mode\n\n  Loads OpenSBI       Loads the kernel\n  into RAM.           and device tree\n                      into RAM\n</code></pre> <p>Such an architecture is not only simpler, but it also enables writing a single kernel for all RISC-V CPUs that implment SBI. SBI puts a layer of abstraction between the hardward and our kernel. SBI also provides functionality like printing and a Flattened Device Tree (FDT).</p> <p>Interacting with SBI is handled by the <code>sbi</code> crate. This crate utilizes the <code>ecall</code> instruction to trap into the SEE (which is OpenSBI on QEMU), where a handler will handle the trap and then return to the kernel. This is handled much in the same way that a system call is handled: first, you set up registers, then you execute <code>ecall</code>, and then you read out registers that contain return values.</p> <p>unCORE currently uses <code>riscv-rt</code>. This crate provides a run-time for RISC-V and additionally handlers for interrupts and exceptions. The linker script currently in use for RISC-V 64bit is derived from the linker script that <code>riscv-rt</code> ships. QEMU takes an ELF file with the <code>-kernel</code> parameter. The ELF is built according to our linker script.</p> <p>When OpenSBI and <code>riscv-rt</code> have finished running, unCORE is entered. The entry functions lives (as the only function) in <code>code/uncore/src/main.rs</code>:</p> unCORE Entry Function Signature<pre><code>/// The RISC-V 64bit entrypoint, called by the [`riscv-rt`] runtime after SBI has set up\n/// the machine.\n#[cfg(target_arch = \"riscv64\")]\n#[riscv_rt::entry]\nfn riscv64_entry(hart: usize) -&gt; ! {\n</code></pre> <p>The entry function is called with one argument, the HART (CPU core; in RISC-V slang \"hardware thread\", i.e., HART) on which the setup has been called. This will prove useful because some system initialization steps need to happen only once, and some have to happen for each HART.</p>","tags":["kernel architecture","kernel architecture","kernel structure","kernel structure","RISC-V"]}]}